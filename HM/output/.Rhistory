source("reselect_winners.R")
data <- data %>% filter(Speaker=="HM")
source("data_preparation.R")
source("reselect_winners.R")
## Graphing monophthongs individually by speaker
library(joeyr)
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
source("data_preparation.R")
source("reselect_winners.R")
source("calculating_exclusions.R")
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
source("data_preparation.R")
source("reselect_winners.R")
library(joeyr)
library(yarrr)
data$omit <- ifelse(data$filename %in% list_to_omit_LV |
data$filename %in% list_to_omit_IN |
data$filename %in% list_to_omit_HM  , 1, data$omit)
filtered <- data %>% filter(omit == 0)
# Recoding the ones that could be o/a as oa
filtered$vowel <- ifelse(filtered$aole==1 | filtered$aohe==1 | filtered$hope==1,
ifelse(filtered$stress=="primary","oa", filtered$vowel), filtered$vowel)
filtered <- filtered %>% filter(articles == 0,
particles == 0,
funct == 0,
demons == 0,
interrogatives == 0,
mea == 0,
manawa == 0)
vowel_token_freq <- as.data.frame(table(filtered$vowel))
vowel_token_freq <- vowel_token_freq %>% rename(vowel = Var1)
ggplot(vowel_token_freq, aes(x=reorder(vowel,-Freq), y=Freq)) +
geom_bar(stat = "identity")+
ggtitle("Token frequency by vowel") +
xlab("Vowel") + ylab("Frequency")+
geom_text(aes(label=Freq), position=position_dodge(width=0.9), vjust=-0.25)
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
datagather <- datagather[,names(datagather) != "Formant.Time"]
dataspread <- datagather %>% spread(formant, Hertz)
dataspread <- dataspread %>% group_by(Speaker) %>% group_by(vowel) %>% mutate(mahal_dist = tidy_mahalanobis(f1, f2))
LV <- dataspread %>% filter(Speaker == "LV") %>% arrange(mahal_dist)
HM <- dataspread %>% filter(Speaker == "HM") %>% arrange(mahal_dist)
IN <- dataspread %>% filter(Speaker == "IN") %>% arrange(mahal_dist)
JM <- dataspread %>% filter(Speaker == "JM") %>% arrange(mahal_dist)
mahal95LV <- c(LV[round(nrow(LV)*0.95),49]) # 49 is the number of columns
mahal95LV
mahal95HM <- c(HM[round(nrow(HM)*0.95),49]) # 49 is the number of columns
mahal95HM
mahal95IN <- c(IN[round(nrow(IN)*0.95),49]) # 49 is the number of columns
mahal95IN
mahal95JM <- c(JM[round(nrow(JM)*0.95),49]) # 49 is the number of columns
mahal95JM
mahal_meansLV <- LV %>% group_by(filename,vowel,word,start,stress) %>%
summarise(mahal_mean=mean(mahal_dist),mahal_median=median(mahal_dist)) %>%
arrange(desc(mahal_mean)) %>%
filter(mahal_mean > mahal95LV)
mahal_meansIN <- IN %>% group_by(filename,vowel,word,start,stress) %>%
summarise(mahal_mean=mean(mahal_dist),mahal_median=median(mahal_dist)) %>%
arrange(desc(mahal_mean)) %>%
filter(mahal_mean > mahal95IN)
mahal_meansHM <- HM %>% group_by(filename,vowel,word,start,stress) %>%
summarise(mahal_mean=mean(mahal_dist),mahal_median=median(mahal_dist)) %>%
arrange(desc(mahal_mean)) %>%
filter(mahal_mean > mahal95HM)
## Graphing monophthongs individually by speaker
library(joeyr)
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
source("data_preparation.R")
source("calculating_exclusions.R")
data <- data %>% filter(Speaker=="HM")
data$omit <- ifelse(data$filename %in% list_to_omit_LV |
data$filename %in% list_to_omit_IN, 1, data$omit)
filtered <- data %>% filter(omit == 0)
filtered$vowel <- ifelse(filtered$aole==1 | filtered$aohe==1 | filtered$hope==1,
ifelse(filtered$stress=="primary","oa", filtered$vowel), filtered$vowel)
filtered <- filtered %>% filter(articles == 0,
particles == 0,
funct == 0,
demons == 0,
interrogatives == 0,
mea == 0,
manawa == 0)
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
datagather <- datagather[,names(datagather) != "Formant.Time"]
dataspread <- datagather %>% spread(formant, Hertz)
dataspread <- dataspread %>% group_by(Speaker) %>% group_by(vowel) %>% mutate(mahal_dist = tidy_mahalanobis(f1, f2))
mahal95 <- c(dataspread[round(nrow(dataspread)*0.95),49]) # 49 is the number of columns
mahal95
View(dataspread)
dataspread <- dataspread %>%
group_by(Speaker) %>%
group_by(vowel) %>%
mutate(mahal_dist = tidy_mahalanobis(f1, f2)) %>%
arrange(mahal_dist)
mahal95 <- c(dataspread[round(nrow(dataspread)*0.95),49]) # 49 is the number of columns
mahal95
dataspread <- dataspread %>% filter(mahal_dist < mahal95)
## Find and add in the midpoints
## Getting which point is the midpoint for each vowel, since some of the midpoints have now been excluded due to being outliers
midpoints <- dataspread %>%
group_by(filename) %>%
mutate(midpoint = time) %>%
slice(which.min(abs(time - 5.1))) %>%
ungroup %>%
select(filename,midpoint)
data_midpoints <- left_join(dataspread,midpoints, by="filename") %>%
filter(time==midpoint) %>%
rename(f1_mid = f1, f2_mid = f2) %>%
ungroup() %>%
select(filename,f1_mid,f2_mid, midpoint)
## Now get max/min F1 and F2 points
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
data <- dataspread
source("max_min_points.R")
## This merges these readings into a single dataframe such that a/ā are measured at Max F1, etc.
max_f1 <- max_f1 %>% filter(vowel=="a"|vowel=="ā")
max_f2 <- max_f2 %>% filter(vowel=="e"|vowel=="ē"|vowel=="i"|vowel=="ī")
min_f2 <- min_f2 %>% filter(vowel=="o"|vowel=="ō"|vowel=="u"|vowel=="ū"|vowel=="oa") # putting oa with /o/ rather than /a/ because when checking the midpoint plots, it looks like this is a more accurate representation of the proper measurement. still picks up on the lowering but does not force it.
monophthongs <- rbind(max_f1,max_f2,min_f2) %>% select(-max_f1,-max_f2,-min_f2)
## Add back in the midpoint columns
monophthongs <- left_join(monophthongs, data_midpoints, by="filename")
## Rename so itʻs clear that f1/f2/f3 are of the inflection point
monophthongs <- monophthongs %>% rename(f1_inf = f1,
f2_inf = f2,
f3_inf = f3,
inf_time = time)
View(monophthongs)
mahal95 <- c(dataspread[round(nrow(dataspread)*0.98),49]) # 49 is the number of columns
mahal95
dataspread <- dataspread %>%
group_by(Speaker) %>%
group_by(vowel) %>%
mutate(mahal_dist = tidy_mahalanobis(f1, f2)) %>%
arrange(mahal_dist)
mahal95 <- c(dataspread[round(nrow(dataspread)*0.98),49]) # 49 is the number of columns
mahal95
mahal95 <- c(dataspread[round(nrow(dataspread)*0.95),49]) # 49 is the number of columns
mahal95
data <- data %>% filter(Speaker=="HM")
## Taking out tokens that should be skipped b/c disfluencies and duration/not measured
data$omit <- ifelse(data$filename %in% list_to_omit_LV |
data$filename %in% list_to_omit_IN, 1, data$omit)
filtered <- data %>% filter(omit == 0)
filtered$vowel <- ifelse(filtered$aole==1 | filtered$aohe==1 | filtered$hope==1,
ifelse(filtered$stress=="primary","oa", filtered$vowel), filtered$vowel)
### Taking out just articles, particles, function words, demonstratives, interrogatives, mea, manawa
### Leaving in pronouns, ʻae, directionals
filtered <- filtered %>% filter(articles == 0,
particles == 0,
funct == 0,
demons == 0,
interrogatives == 0,
mea == 0,
manawa == 0)
######### SPREADING DATA INTO TALL FORMAT #########
## Get a spread dataset for things that require long form data, like trajectories
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
datagather <- datagather[,names(datagather) != "Formant.Time"]
dataspread <- datagather %>% spread(formant, Hertz)
## Adding a column for mahalanobis distance
dataspread <- dataspread %>%
group_by(Speaker) %>%
group_by(vowel) %>%
mutate(mahal_dist = tidy_mahalanobis(f1, f2)) %>%
arrange(mahal_dist)
source("data_preparation.R")
source("calculating_exclusions.R")
data <- data %>% filter(Speaker=="HM")
data$omit <- ifelse(data$filename %in% list_to_omit_LV |
data$filename %in% list_to_omit_IN, 1, data$omit)
filtered <- data %>% filter(omit == 0)
filtered$vowel <- ifelse(filtered$aole==1 | filtered$aohe==1 | filtered$hope==1,
ifelse(filtered$stress=="primary","oa", filtered$vowel), filtered$vowel)
filtered <- filtered %>% filter(articles == 0,
particles == 0,
funct == 0,
demons == 0,
interrogatives == 0,
mea == 0,
manawa == 0)
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
datagather <- datagather[,names(datagather) != "Formant.Time"]
dataspread <- datagather %>% spread(formant, Hertz)
dataspread <- dataspread %>%
group_by(Speaker) %>%
group_by(vowel) %>%
mutate(mahal_dist = tidy_mahalanobis(f1, f2)) %>%
arrange(mahal_dist)
mahal95 <- c(dataspread[round(nrow(dataspread)*0.95),49]) # 49 is the number of columns
mahal95
mahal95 <- c(dataspread[round(nrow(dataspread)*0.98),49]) # 49 is the number of columns
mahal95
mahal95 <- c(dataspread[round(nrow(dataspread)*0.99),49]) # 49 is the number of columns
mahal95
dataspread <- dataspread %>% filter(mahal_dist < mahal95)
midpoints <- dataspread %>%
group_by(filename) %>%
mutate(midpoint = time) %>%
slice(which.min(abs(time - 5.1))) %>%
ungroup %>%
select(filename,midpoint)
data_midpoints <- left_join(dataspread,midpoints, by="filename") %>%
filter(time==midpoint) %>%
rename(f1_mid = f1, f2_mid = f2) %>%
ungroup() %>%
select(filename,f1_mid,f2_mid, midpoint)
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
data <- dataspread
source("max_min_points.R")
max_f1 <- max_f1 %>% filter(vowel=="a"|vowel=="ā")
max_f2 <- max_f2 %>% filter(vowel=="e"|vowel=="ē"|vowel=="i"|vowel=="ī")
min_f2 <- min_f2 %>% filter(vowel=="o"|vowel=="ō"|vowel=="u"|vowel=="ū"|vowel=="oa") # putting oa with /o/ rather than /a/ because when checking the midpoint plots, it looks like this is a more accurate representation of the proper measurement. still picks up on the lowering but does not force it.
monophthongs <- rbind(max_f1,max_f2,min_f2) %>% select(-max_f1,-max_f2,-min_f2)
monophthongs <- left_join(monophthongs, data_midpoints, by="filename")
monophthongs <- monophthongs %>% rename(f1_inf = f1,
f2_inf = f2,
f3_inf = f3,
inf_time = time)
View(monophthongs)
## Graphing monophthongs individually by speaker
library(joeyr)
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
source("data_preparation.R")
source("calculating_exclusions.R")
## Set the speaker to look at
data <- data %>% filter(Speaker=="IN")
## Taking out tokens that should be skipped b/c disfluencies and duration/not measured
data$omit <- ifelse(data$filename %in% list_to_omit_LV |
data$filename %in% list_to_omit_IN, 1, data$omit)
filtered <- data %>% filter(omit == 0)
filtered$vowel <- ifelse(filtered$aole==1 | filtered$aohe==1 | filtered$hope==1,
ifelse(filtered$stress=="primary","oa", filtered$vowel), filtered$vowel)
### Taking out just articles, particles, function words, demonstratives, interrogatives, mea, manawa
### Leaving in pronouns, ʻae, directionals
filtered <- filtered %>% filter(articles == 0,
particles == 0,
funct == 0,
demons == 0,
interrogatives == 0,
mea == 0,
manawa == 0)
######### SPREADING DATA INTO TALL FORMAT #########
## Get a spread dataset for things that require long form data, like trajectories
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
datagather <- datagather[,names(datagather) != "Formant.Time"]
dataspread <- datagather %>% spread(formant, Hertz)
## Adding a column for mahalanobis distance
dataspread <- dataspread %>%
group_by(Speaker) %>%
group_by(vowel) %>%
mutate(mahal_dist = tidy_mahalanobis(f1, f2)) %>%
arrange(mahal_dist)
## By-mesurement Exclusions: Remove columns with mahal dist higher than the 95th percentile as established earlier
mahal95 <- c(dataspread[round(nrow(dataspread)*0.95),49]) # 49 is the number of columns
mahal95
View(dataspread)
dataspread <- dataspread %>% filter(mahal_dist < mahal95)
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
datagather <- datagather[,names(datagather) != "Formant.Time"]
dataspread <- datagather %>% spread(formant, Hertz)
## Adding a column for mahalanobis distance
dataspread <- dataspread %>%
group_by(Speaker) %>%
group_by(vowel) %>%
mutate(mahal_dist = tidy_mahalanobis(f1, f2)) %>%
arrange(mahal_dist)
## By-mesurement Exclusions: Remove columns with mahal dist higher than the 95th percentile as established earlier
mahal95 <- c(dataspread[round(nrow(dataspread)*0.99),49]) # 49 is the number of columns
mahal95
mahal95
dataspread <- dataspread %>% filter(mahal_dist < mahal95)
source("data_preparation.R")
source("calculating_exclusions.R")
## Graphing monophthongs individually by speaker
library(joeyr)
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
source("data_preparation.R")
source("calculating_exclusions.R")
data <- data %>% filter(Speaker=="LV")
data <- data %>% filter(Speaker=="LV")
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
datagather <- datagather[,names(datagather) != "Formant.Time"]
dataspread <- datagather %>% spread(formant, Hertz)
dataspread <- dataspread %>%
group_by(Speaker) %>%
group_by(vowel) %>%
mutate(mahal_dist = tidy_mahalanobis(f1, f2)) %>%
arrange(mahal_dist)
mahal99 <- c(dataspread[round(nrow(dataspread)*0.99),49]) # 49 is the number of columns
mahal99
dataspread <- dataspread %>% filter(mahal_dist < mahal95)
View(dataspread)
data <- data %>% filter(Speaker=="LV")
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
## Graphing monophthongs individually by speaker
library(joeyr)
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
source("data_preparation.R")
source("calculating_exclusions.R")
dataspread <- dataspread %>% filter(Speaker=="LV")
mahal99 <- c(dataspread[round(nrow(dataspread)*0.99),49]) # 49 is the number of columns
mahal99
View(dataspread)
dataspread <- dataspread %>%
filter(Speaker=="LV") %>%
arrange(mahal_dist)
mahal99 <- c(dataspread[round(nrow(dataspread)*0.99),49]) # 49 is the number of columns
mahal99
mahal99 <- c(dataspread[round(nrow(dataspread)*0.95),49]) # 49 is the number of columns
mahal99
mahal95 <- c(dataspread[round(nrow(dataspread)*0.95),49]) # 49 is the number of columns
mahal95
m95 <- dataspread %>% filter(mahal_dist < mahal95)
m99 <- dataspread %>% filter(mahal_dist < mahal95)
View(m95)
View(m99)
mahal99 <- c(dataspread[round(nrow(dataspread)*0.99),49]) # 49 is the number of columns
mahal99
mahal95 <- c(dataspread[round(nrow(dataspread)*0.95),49]) # 49 is the number of columns
mahal95
m99 <- dataspread %>% filter(mahal_dist < mahal99)
View(m99)
library(joeyr)
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
source("data_preparation.R")
source("calculating_exclusions.R")
## Set the speaker to look at
dataspread <- dataspread %>%
filter(Speaker=="LV") %>%
arrange(mahal_dist)
dataspread <- dataspread %>% filter(mahal_dist < mahal99)
View(dataspread)
mahal99 <- c(dataspread[round(nrow(dataspread)*0.99),49]) # 49 is the number of columns
mahal99
dataspread <- dataspread %>% filter(mahal_dist < mahal99)
midpoints <- dataspread %>%
group_by(filename) %>%
mutate(midpoint = time) %>%
slice(which.min(abs(time - 5.1))) %>%
ungroup %>%
select(filename,midpoint)
data_midpoints <- left_join(dataspread,midpoints, by="filename") %>%
filter(time==midpoint) %>%
rename(f1_mid = f1, f2_mid = f2) %>%
ungroup() %>%
select(filename,f1_mid,f2_mid, midpoint)
setwd("/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/R_scripts/")
data <- dataspread
source("max_min_points.R")
max_f1 <- max_f1 %>% filter(vowel=="a"|vowel=="ā")
max_f2 <- max_f2 %>% filter(vowel=="e"|vowel=="ē"|vowel=="i"|vowel=="ī")
min_f2 <- min_f2 %>% filter(vowel=="o"|vowel=="ō"|vowel=="u"|vowel=="ū"|vowel=="oa") # putting oa with /o/ rather than /a/ because when checking the midpoint plots, it looks like this is a more accurate representation of the proper measurement. still picks up on the lowering but does not force it.
monophthongs <- rbind(max_f1,max_f2,min_f2) %>% select(-max_f1,-max_f2,-min_f2)
monophthongs <- left_join(monophthongs, data_midpoints, by="filename")
monophthongs <- monophthongs %>% rename(f1_inf = f1,
f2_inf = f2,
f3_inf = f3,
inf_time = time)
monophthongs <- monophthongs %>% filter(next_sound %notin% list_of_vowels , previous_sound %notin% list_of_vowels)
monophthongs <- monophthongs %>% filter(pronouns == 0,
directionals == 0)
## Getting dataframes for all, just primary, and primary+secondary
monophthongs <- monophthongs %>% filter(stress!="0")
mono_primary <- monophthongs %>% filter(stress=="primary")
mono_primary_secondary <- monophthongs %>% filter(stress=="primary"|stress=="secondary")
# Dataframe for means of monophthongs overall
mono_means <- monophthongs %>%
group_by(vowel) %>%
summarise(mean_f1_inf = mean(f1_inf),
mean_f2_inf = mean(f2_inf),
mean_f1_mid = mean(f1_mid),
mean_f2_mid = mean(f2_mid))
# Dataframe for means of just primary monophthongs
mono_primary_means <- mono_primary %>%
group_by(vowel) %>%
summarise(mean_f1_inf = mean(f1_inf),
mean_f2_inf = mean(f2_inf),
mean_f1_mid = mean(f1_mid),
mean_f2_mid = mean(f2_mid))
# Dataframe for means of just primary and secondary monophthongs
mono_primary_secondary_means <- mono_primary_secondary %>%
group_by(vowel) %>%
summarise(mean_f1_inf = mean(f1_inf),
mean_f2_inf = mean(f2_inf),
mean_f1_mid = mean(f1_mid),
mean_f2_mid = mean(f2_mid))
ggplot() +
geom_text(data = mono_means, aes(x = mean_f2, y = mean_f1, color = vowel, label = vowel)) +
stat_ellipse(data = monophthongs, aes(x = f2, y = f1, color = vowel), level = 0.67) +
scale_x_reverse() + scale_y_reverse() +
theme_classic() +
labs(title = "Overall means of monophthongs, all stress environments", x = "F2", y = "F1") +
theme(legend.position = "", plot.title = element_text(hjust = 0.5))
ggplot() +
geom_text(data = mono_primary_means, aes(x = mean_f2, y = mean_f1, color = vowel, label = vowel)) +
stat_ellipse(data = mono_primary, aes(x = f2, y = f1, color = vowel), level = 0.67) +
geom_point(data = mono_primary, aes(x = f2, y= f1, color=vowel), size=1, alpha=0.2) +
scale_x_reverse() + scale_y_reverse() +
theme_classic() +
labs(title = "Overall means of monophthongs, primary stress", x = "F2", y = "F1") +
theme(legend.position = "", plot.title = element_text(hjust = 0.5))
## Overall means of mono, primary and secondary, using inflection points
ggplot() +
geom_text(data = mono_primary_secondary_means, aes(x = mean_f2_inf, y = mean_f1_inf, color = vowel, label = vowel)) +
stat_ellipse(data = mono_primary_secondary, aes(x = f2_inf, y = f1_inf, color = vowel), level = 0.67) +
scale_x_reverse() + scale_y_reverse() +
geom_point(data = mono_primary_secondary, aes(x = f2_inf, y= f1_inf, color=vowel), size=1, alpha=0.2) +
theme_classic() +
labs(title = "Overall means of monophthongs, primary and secondary stress", x = "F2", y = "F1") +
theme(legend.position = "", plot.title = element_text(hjust = 0.5))
ggplot() +
geom_text(data = mono_primary_secondary_means, aes(x = mean_f2_mid, y = mean_f1_mid, color = vowel, label = vowel)) +
stat_ellipse(data = mono_primary_secondary, aes(x = f2_mid, y = f1_mid, color = vowel), level = 0.67) +
scale_x_reverse() + scale_y_reverse() +
geom_point(data = mono_primary_secondary, aes(x = f2_mid, y= f1_mid, color=vowel), size=1, alpha=0.2) +
theme_classic() +
labs(title = "Overall means of monophthongs, primary and secondary stress", x = "F2", y = "F1") +
theme(legend.position = "", plot.title = element_text(hjust = 0.5))
ggplot() +
geom_text(data = mono_primary_secondary_means, aes(x = mean_f2_mid, y = mean_f1_mid, color = vowel, label = vowel)) +
stat_ellipse(data = mono_primary_secondary, aes(x = f2_mid, y = f1_mid, color = vowel), level = 0.67) +
scale_x_reverse() + scale_y_reverse() +
geom_point(data = mono_primary_secondary, aes(x = f2_mid, y= f1_mid, color=vowel), size=1, alpha=0.2) +
theme_classic() +
labs(title = "Overall means of monophthongs, primary and secondary stress", x = "F2", y = "F1") +
theme(legend.position = "", plot.title = element_text(hjust = 0.5))
ggplot() +
geom_text(data = mono_primary_secondary_means, aes(x = mean_f2_inf, y = mean_f1_inf, color = vowel, label = vowel)) +
stat_ellipse(data = mono_primary_secondary, aes(x = f2_inf, y = f1_inf, color = vowel), level = 0.67) +
scale_x_reverse() + scale_y_reverse() +
geom_point(data = mono_primary_secondary, aes(x = f2_inf, y= f1_inf, color=vowel), size=1, alpha=0.2) +
theme_classic() +
labs(title = "Overall means of monophthongs, primary and secondary stress", x = "F2", y = "F1") +
theme(legend.position = "", plot.title = element_text(hjust = 0.5))
source("data_preparation.R")
source("reselect_winners.R")
library(joeyr)
library(yarrr)
data$omit <- ifelse(data$filename %in% list_to_omit_LV |
data$filename %in% list_to_omit_IN |
data$filename %in% list_to_omit_HM  , 1, data$omit)
filtered <- data %>% filter(omit == 0)
# Recoding the ones that could be o/a as oa
filtered$vowel <- ifelse(filtered$aole==1 | filtered$aohe==1 | filtered$hope==1,
ifelse(filtered$stress=="primary","oa", filtered$vowel), filtered$vowel)
filtered <- filtered %>% filter(articles == 0,
particles == 0,
funct == 0,
demons == 0,
interrogatives == 0,
mea == 0,
manawa == 0)
### Gets number of tokens per vowel
vowel_token_freq <- as.data.frame(table(filtered$vowel))
vowel_token_freq <- vowel_token_freq %>% rename(vowel = Var1)
ggplot(vowel_token_freq, aes(x=reorder(vowel,-Freq), y=Freq)) +
geom_bar(stat = "identity")+
ggtitle("Token frequency by vowel") +
xlab("Vowel") + ylab("Frequency")+
geom_text(aes(label=Freq), position=position_dodge(width=0.9), vjust=-0.25)
######### SPREADING DATA INTO TALL FORMAT #########
## Get a spread dataset for things that require long form data, like trajectories
datagather <- filtered %>% gather(Formant.Time, Hertz, f1.1:f3.9)
datagather <- data.frame(datagather, reshape2::colsplit(datagather$Formant.Time, pattern="\\.", names = c("formant", "time")))
datagather <- datagather[,names(datagather) != "Formant.Time"]
dataspread <- datagather %>% spread(formant, Hertz)
## Adding a column for mahalanobis distance
dataspread <- dataspread %>% group_by(Speaker) %>% group_by(vowel) %>% mutate(mahal_dist = tidy_mahalanobis(f1, f2))
## Going to rearrange data by mahal distance for each speaker
LV <- dataspread %>% filter(Speaker == "LV") %>% arrange(mahal_dist)
HM <- dataspread %>% filter(Speaker == "HM") %>% arrange(mahal_dist)
IN <- dataspread %>% filter(Speaker == "IN") %>% arrange(mahal_dist)
JM <- dataspread %>% filter(Speaker == "JM") %>% arrange(mahal_dist)
## Find the 95% point in them, if we want to just explore worst 5% of data
mahal95LV <- c(LV[round(nrow(LV)*0.95),49]) # 49 is the number of columns
mahal95LV
mahal95HM <- c(HM[round(nrow(HM)*0.95),49]) # 49 is the number of columns
mahal95HM
mahal95IN <- c(IN[round(nrow(IN)*0.95),49]) # 49 is the number of columns
mahal95IN
mahal95JM <- c(JM[round(nrow(JM)*0.95),49]) # 49 is the number of columns
mahal95JM
## Let's group by token first and then figure out the tokens that have the worst mahal means and medians
## of all 9 of their readings. This will be useful for spot-checking!
mahal_meansLV <- LV %>% group_by(filename,vowel,word,start,stress) %>%
summarise(mahal_mean=mean(mahal_dist),mahal_median=median(mahal_dist)) %>%
arrange(desc(mahal_mean)) %>%
filter(mahal_mean > mahal95LV)
# write.csv(mahal_meansLV, "/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/Manaleo/LV/output/mahal_means.csv")
mahal_meansIN <- IN %>% group_by(filename,vowel,word,start,stress) %>%
summarise(mahal_mean=mean(mahal_dist),mahal_median=median(mahal_dist)) %>%
arrange(desc(mahal_mean)) %>%
filter(mahal_mean > mahal95IN)
# write.csv(mahal_meansIN, "/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/Manaleo/IN/output/mahal_means.csv")
mahal_meansHM <- HM %>% group_by(filename,vowel,word,start,stress) %>%
summarise(mahal_mean=mean(mahal_dist),mahal_median=median(mahal_dist)) %>%
arrange(desc(mahal_mean)) %>%
filter(mahal_mean > mahal95HM)
# write.csv(mahal_meansHM, "/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/Manaleo/HM/output/mahal_means.csv")
mahal_meansJM <- JM %>% group_by(filename,vowel,word,start,stress) %>%
summarise(mahal_mean=mean(mahal_dist),mahal_median=median(mahal_dist)) %>%
arrange(desc(mahal_mean)) %>%
filter(mahal_mean > mahal95JM)
write.csv(mahal_meansJM, "/Users/Thomas/Documents/Hawaiian_Phonetics/Dissertation/Manaleo/JM/output/mahal_means.csv")
